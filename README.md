# Customized AI chatbot assistant
A Python-based UI that accepts a prompt and a PDF or XLSX file, then sends them to an Ollama model, which returns an answer related to the user’s question. This project was created for testing and learning purposes.

## Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [Contact](#contact)

## Features

- Document Processing
- Conversation
- User Interface
- Performance Optimization

## Installation

### Prerequisites
- Python 3.8+
- Ollama installed and running locally (https://ollama.ai)

### Setup

```bash
# Clone the repository
git clone https://github.com/ItsAalex/customized-chatbot-assistant.git

# Navigate to project directory
cd customized-chatbot-assistant

# Install dependencies
pip install -r requirements.txt

# Verify Ollama is running
ollama serve  # Run in another terminal

# Run the application
streamlit run app.py
```

## Usage

### Basic Usage

```bash
# Command to run the project
streamlit run app.py
```

## Project Structure

```
project-root/
├── app.py            # Main python file
├── README.md         # README file
├── requirements.txt  # Dependencies and requirements file
```

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the project
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## Acknowledgments

- Credit any libraries, tools, or people who helped
- Link to resources or inspiration
- Mention any related projects

## Contact

Aleksandar Cvetkovic - aleksandarcvetkovic756@gmail.com

### Screenshots (COMING SOON)

![App Screenshot](path/to/screenshot.png)
